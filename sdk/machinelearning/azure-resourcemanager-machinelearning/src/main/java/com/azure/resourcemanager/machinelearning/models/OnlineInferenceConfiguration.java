// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.resourcemanager.machinelearning.models;

import com.azure.core.annotation.Fluent;
import com.fasterxml.jackson.annotation.JsonInclude;
import com.fasterxml.jackson.annotation.JsonProperty;
import java.util.Map;

/** Online inference configuration options. */
@Fluent
public final class OnlineInferenceConfiguration {
    /*
     * Additional configurations
     */
    @JsonProperty(value = "configurations")
    @JsonInclude(value = JsonInclude.Include.NON_NULL, content = JsonInclude.Include.ALWAYS)
    private Map<String, String> configurations;

    /*
     * Entry script or command to invoke.
     */
    @JsonProperty(value = "entryScript")
    private String entryScript;

    /*
     * The route to check the liveness of the inference server container.
     */
    @JsonProperty(value = "livenessRoute")
    private Route livenessRoute;

    /*
     * The route to check the readiness of the inference server container.
     */
    @JsonProperty(value = "readinessRoute")
    private Route readinessRoute;

    /*
     * The port to send the scoring requests to, within the inference server container.
     */
    @JsonProperty(value = "scoringRoute")
    private Route scoringRoute;

    /** Creates an instance of OnlineInferenceConfiguration class. */
    public OnlineInferenceConfiguration() {
    }

    /**
     * Get the configurations property: Additional configurations.
     *
     * @return the configurations value.
     */
    public Map<String, String> configurations() {
        return this.configurations;
    }

    /**
     * Set the configurations property: Additional configurations.
     *
     * @param configurations the configurations value to set.
     * @return the OnlineInferenceConfiguration object itself.
     */
    public OnlineInferenceConfiguration withConfigurations(Map<String, String> configurations) {
        this.configurations = configurations;
        return this;
    }

    /**
     * Get the entryScript property: Entry script or command to invoke.
     *
     * @return the entryScript value.
     */
    public String entryScript() {
        return this.entryScript;
    }

    /**
     * Set the entryScript property: Entry script or command to invoke.
     *
     * @param entryScript the entryScript value to set.
     * @return the OnlineInferenceConfiguration object itself.
     */
    public OnlineInferenceConfiguration withEntryScript(String entryScript) {
        this.entryScript = entryScript;
        return this;
    }

    /**
     * Get the livenessRoute property: The route to check the liveness of the inference server container.
     *
     * @return the livenessRoute value.
     */
    public Route livenessRoute() {
        return this.livenessRoute;
    }

    /**
     * Set the livenessRoute property: The route to check the liveness of the inference server container.
     *
     * @param livenessRoute the livenessRoute value to set.
     * @return the OnlineInferenceConfiguration object itself.
     */
    public OnlineInferenceConfiguration withLivenessRoute(Route livenessRoute) {
        this.livenessRoute = livenessRoute;
        return this;
    }

    /**
     * Get the readinessRoute property: The route to check the readiness of the inference server container.
     *
     * @return the readinessRoute value.
     */
    public Route readinessRoute() {
        return this.readinessRoute;
    }

    /**
     * Set the readinessRoute property: The route to check the readiness of the inference server container.
     *
     * @param readinessRoute the readinessRoute value to set.
     * @return the OnlineInferenceConfiguration object itself.
     */
    public OnlineInferenceConfiguration withReadinessRoute(Route readinessRoute) {
        this.readinessRoute = readinessRoute;
        return this;
    }

    /**
     * Get the scoringRoute property: The port to send the scoring requests to, within the inference server container.
     *
     * @return the scoringRoute value.
     */
    public Route scoringRoute() {
        return this.scoringRoute;
    }

    /**
     * Set the scoringRoute property: The port to send the scoring requests to, within the inference server container.
     *
     * @param scoringRoute the scoringRoute value to set.
     * @return the OnlineInferenceConfiguration object itself.
     */
    public OnlineInferenceConfiguration withScoringRoute(Route scoringRoute) {
        this.scoringRoute = scoringRoute;
        return this;
    }

    /**
     * Validates the instance.
     *
     * @throws IllegalArgumentException thrown if the instance is not valid.
     */
    public void validate() {
        if (livenessRoute() != null) {
            livenessRoute().validate();
        }
        if (readinessRoute() != null) {
            readinessRoute().validate();
        }
        if (scoringRoute() != null) {
            scoringRoute().validate();
        }
    }
}
