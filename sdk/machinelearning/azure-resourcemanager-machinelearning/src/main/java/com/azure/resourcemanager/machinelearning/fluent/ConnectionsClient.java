// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.resourcemanager.machinelearning.fluent;

import com.azure.core.annotation.ReturnType;
import com.azure.core.annotation.ServiceMethod;
import com.azure.core.http.rest.PagedIterable;
import com.azure.core.http.rest.Response;
import com.azure.core.management.polling.PollResult;
import com.azure.core.util.Context;
import com.azure.core.util.polling.SyncPoller;
import com.azure.resourcemanager.machinelearning.fluent.models.EndpointDeploymentResourcePropertiesBasicResourceInner;
import com.azure.resourcemanager.machinelearning.fluent.models.EndpointModelPropertiesInner;
import com.azure.resourcemanager.machinelearning.fluent.models.EndpointModelsInner;

/**
 * An instance of this class provides access to all the operations defined in ConnectionsClient.
 */
public interface ConnectionsClient {
    /**
     * Get all the deployments under the Azure OpenAI connection.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Azure Machine Learning Workspace Name.
     * @param connectionName Friendly name of the workspace connection.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return all the deployments under the Azure OpenAI connection as paginated response with {@link PagedIterable}.
     */
    @ServiceMethod(returns = ReturnType.COLLECTION)
    PagedIterable<EndpointDeploymentResourcePropertiesBasicResourceInner> listDeployments(String resourceGroupName,
        String workspaceName, String connectionName);

    /**
     * Get all the deployments under the Azure OpenAI connection.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Azure Machine Learning Workspace Name.
     * @param connectionName Friendly name of the workspace connection.
     * @param proxyApiVersion Api version used by proxy call.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return all the deployments under the Azure OpenAI connection as paginated response with {@link PagedIterable}.
     */
    @ServiceMethod(returns = ReturnType.COLLECTION)
    PagedIterable<EndpointDeploymentResourcePropertiesBasicResourceInner> listDeployments(String resourceGroupName,
        String workspaceName, String connectionName, String proxyApiVersion, Context context);

    /**
     * Delete Azure OpenAI connection deployment resource by name.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Azure Machine Learning Workspace Name.
     * @param connectionName Friendly name of the workspace connection.
     * @param deploymentName Name of the deployment resource.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the {@link SyncPoller} for polling of long-running operation.
     */
    @ServiceMethod(returns = ReturnType.LONG_RUNNING_OPERATION)
    SyncPoller<PollResult<Void>, Void> beginDeleteDeployment(String resourceGroupName, String workspaceName,
        String connectionName, String deploymentName);

    /**
     * Delete Azure OpenAI connection deployment resource by name.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Azure Machine Learning Workspace Name.
     * @param connectionName Friendly name of the workspace connection.
     * @param deploymentName Name of the deployment resource.
     * @param proxyApiVersion Api version used by proxy call.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the {@link SyncPoller} for polling of long-running operation.
     */
    @ServiceMethod(returns = ReturnType.LONG_RUNNING_OPERATION)
    SyncPoller<PollResult<Void>, Void> beginDeleteDeployment(String resourceGroupName, String workspaceName,
        String connectionName, String deploymentName, String proxyApiVersion, Context context);

    /**
     * Delete Azure OpenAI connection deployment resource by name.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Azure Machine Learning Workspace Name.
     * @param connectionName Friendly name of the workspace connection.
     * @param deploymentName Name of the deployment resource.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    void deleteDeployment(String resourceGroupName, String workspaceName, String connectionName, String deploymentName);

    /**
     * Delete Azure OpenAI connection deployment resource by name.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Azure Machine Learning Workspace Name.
     * @param connectionName Friendly name of the workspace connection.
     * @param deploymentName Name of the deployment resource.
     * @param proxyApiVersion Api version used by proxy call.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    void deleteDeployment(String resourceGroupName, String workspaceName, String connectionName, String deploymentName,
        String proxyApiVersion, Context context);

    /**
     * Get deployments under the Azure OpenAI connection by name.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Azure Machine Learning Workspace Name.
     * @param connectionName Friendly name of the workspace connection.
     * @param deploymentName Name of the deployment resource.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return deployments under the Azure OpenAI connection by name along with {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    Response<EndpointDeploymentResourcePropertiesBasicResourceInner> getDeploymentWithResponse(String resourceGroupName,
        String workspaceName, String connectionName, String deploymentName, Context context);

    /**
     * Get deployments under the Azure OpenAI connection by name.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Azure Machine Learning Workspace Name.
     * @param connectionName Friendly name of the workspace connection.
     * @param deploymentName Name of the deployment resource.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return deployments under the Azure OpenAI connection by name.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    EndpointDeploymentResourcePropertiesBasicResourceInner getDeployment(String resourceGroupName, String workspaceName,
        String connectionName, String deploymentName);

    /**
     * Create or update Azure OpenAI connection deployment resource with the specified parameters.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Azure Machine Learning Workspace Name.
     * @param connectionName Friendly name of the workspace connection.
     * @param deploymentName Name of the deployment resource.
     * @param body deployment object.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the {@link SyncPoller} for polling of long-running operation.
     */
    @ServiceMethod(returns = ReturnType.LONG_RUNNING_OPERATION)
    SyncPoller<PollResult<EndpointDeploymentResourcePropertiesBasicResourceInner>, EndpointDeploymentResourcePropertiesBasicResourceInner>
        beginCreateOrUpdateDeployment(String resourceGroupName, String workspaceName, String connectionName,
            String deploymentName, EndpointDeploymentResourcePropertiesBasicResourceInner body);

    /**
     * Create or update Azure OpenAI connection deployment resource with the specified parameters.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Azure Machine Learning Workspace Name.
     * @param connectionName Friendly name of the workspace connection.
     * @param deploymentName Name of the deployment resource.
     * @param body deployment object.
     * @param proxyApiVersion Api version used by proxy call.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the {@link SyncPoller} for polling of long-running operation.
     */
    @ServiceMethod(returns = ReturnType.LONG_RUNNING_OPERATION)
    SyncPoller<PollResult<EndpointDeploymentResourcePropertiesBasicResourceInner>, EndpointDeploymentResourcePropertiesBasicResourceInner>
        beginCreateOrUpdateDeployment(String resourceGroupName, String workspaceName, String connectionName,
            String deploymentName, EndpointDeploymentResourcePropertiesBasicResourceInner body, String proxyApiVersion,
            Context context);

    /**
     * Create or update Azure OpenAI connection deployment resource with the specified parameters.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Azure Machine Learning Workspace Name.
     * @param connectionName Friendly name of the workspace connection.
     * @param deploymentName Name of the deployment resource.
     * @param body deployment object.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    EndpointDeploymentResourcePropertiesBasicResourceInner createOrUpdateDeployment(String resourceGroupName,
        String workspaceName, String connectionName, String deploymentName,
        EndpointDeploymentResourcePropertiesBasicResourceInner body);

    /**
     * Create or update Azure OpenAI connection deployment resource with the specified parameters.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Azure Machine Learning Workspace Name.
     * @param connectionName Friendly name of the workspace connection.
     * @param deploymentName Name of the deployment resource.
     * @param body deployment object.
     * @param proxyApiVersion Api version used by proxy call.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return the response.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    EndpointDeploymentResourcePropertiesBasicResourceInner createOrUpdateDeployment(String resourceGroupName,
        String workspaceName, String connectionName, String deploymentName,
        EndpointDeploymentResourcePropertiesBasicResourceInner body, String proxyApiVersion, Context context);

    /**
     * Get available models under the Azure OpenAI connection.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Azure Machine Learning Workspace Name.
     * @param connectionName Friendly name of the workspace connection.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return available models under the Azure OpenAI connection as paginated response with {@link PagedIterable}.
     */
    @ServiceMethod(returns = ReturnType.COLLECTION)
    PagedIterable<EndpointModelPropertiesInner> getModels(String resourceGroupName, String workspaceName,
        String connectionName);

    /**
     * Get available models under the Azure OpenAI connection.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Azure Machine Learning Workspace Name.
     * @param connectionName Friendly name of the workspace connection.
     * @param proxyApiVersion Api version used by proxy call.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return available models under the Azure OpenAI connection as paginated response with {@link PagedIterable}.
     */
    @ServiceMethod(returns = ReturnType.COLLECTION)
    PagedIterable<EndpointModelPropertiesInner> getModels(String resourceGroupName, String workspaceName,
        String connectionName, String proxyApiVersion, Context context);

    /**
     * Get models under the Azure ML workspace for all Azure OpenAI connections that the user can deploy.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Azure Machine Learning Workspace Name.
     * @param context The context to associate with this operation.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return models under the Azure ML workspace for all Azure OpenAI connections that the user can deploy along with
     * {@link Response}.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    Response<EndpointModelsInner> getAllModelsWithResponse(String resourceGroupName, String workspaceName,
        Context context);

    /**
     * Get models under the Azure ML workspace for all Azure OpenAI connections that the user can deploy.
     * 
     * @param resourceGroupName The name of the resource group. The name is case insensitive.
     * @param workspaceName Azure Machine Learning Workspace Name.
     * @throws IllegalArgumentException thrown if parameters fail the validation.
     * @throws com.azure.core.management.exception.ManagementException thrown if the request is rejected by server.
     * @throws RuntimeException all other wrapped checked exceptions if the request fails to be sent.
     * @return models under the Azure ML workspace for all Azure OpenAI connections that the user can deploy.
     */
    @ServiceMethod(returns = ReturnType.SINGLE)
    EndpointModelsInner getAllModels(String resourceGroupName, String workspaceName);
}
