// Copyright (c) Microsoft Corporation. All rights reserved.
// Licensed under the MIT License.
// Code generated by Microsoft (R) AutoRest Code Generator.

package com.azure.resourcemanager.machinelearning.models;

import com.azure.core.annotation.Fluent;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonTypeInfo;
import com.fasterxml.jackson.annotation.JsonTypeName;

/** Triton inferencing server configurations. */
@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, include = JsonTypeInfo.As.PROPERTY, property = "serverType")
@JsonTypeName("Triton")
@Fluent
public final class TritonInferencingServer extends InferencingServer {
    /*
     * Inference configuration for Triton.
     */
    @JsonProperty(value = "inferenceConfiguration")
    private OnlineInferenceConfiguration inferenceConfiguration;

    /** Creates an instance of TritonInferencingServer class. */
    public TritonInferencingServer() {
    }

    /**
     * Get the inferenceConfiguration property: Inference configuration for Triton.
     *
     * @return the inferenceConfiguration value.
     */
    public OnlineInferenceConfiguration inferenceConfiguration() {
        return this.inferenceConfiguration;
    }

    /**
     * Set the inferenceConfiguration property: Inference configuration for Triton.
     *
     * @param inferenceConfiguration the inferenceConfiguration value to set.
     * @return the TritonInferencingServer object itself.
     */
    public TritonInferencingServer withInferenceConfiguration(OnlineInferenceConfiguration inferenceConfiguration) {
        this.inferenceConfiguration = inferenceConfiguration;
        return this;
    }

    /**
     * Validates the instance.
     *
     * @throws IllegalArgumentException thrown if the instance is not valid.
     */
    @Override
    public void validate() {
        super.validate();
        if (inferenceConfiguration() != null) {
            inferenceConfiguration().validate();
        }
    }
}
